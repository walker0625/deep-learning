import streamlit as st
import torch
import torch.nn as nn
import torchvision.transforms as transforms
from PIL import Image
from streamlit_drawable_canvas import st_canvas

# --- 1. ëª¨ë¸ ë¡œë”© ë° ì„¤ì • ---
@st.cache_resource
def load_model():
    
    model = nn.Sequential(
        nn.Linear(28 * 28, 128),
        nn.ReLU(),
        nn.Linear(128, 64),
        nn.ReLU(),
        nn.Linear(64, 10),
    )
    
    # try:
        #CPU í™˜ê²½ì—ì„œ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ
        # model.load_state_dict(torch.load('model_pth/model_hand.pth', map_location=torch.device('cpu')))
    # except FileNotFoundError:
        # st.error(f"'{model_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëª¨ë¸ ê°€ì¤‘ì¹˜ íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        # return None
        
    model.eval() # ì¶”ë¡  ëª¨ë“œë¡œ ì„¤ì •
    
    return model

# --- 2. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì„¤ì • ---

transform = transforms.Compose([
    transforms.Grayscale(num_output_channels=1), # í‘ë°±ìœ¼ë¡œ ë³€í™˜
    transforms.Resize((28, 28)),             # MNIST ëª¨ë¸ ì…ë ¥ ì‚¬ì´ì¦ˆì— ë§ê²Œ ì¡°ì •
    transforms.ToTensor(),                         # PyTorch í…ì„œë¡œ ë³€í™˜
])


# --- 3. Streamlit UI êµ¬ì„± ---

st.title("ì†ê¸€ì”¨ ë¶„ë¥˜")
st.write("0-9 ìˆ«ìë¥¼ ì†ìœ¼ë¡œ ê·¸ë¦¬ì‹œì˜¤")

# ìº”ë²„ìŠ¤ UI ì„¤ì •
canvas_result = st_canvas(
    fill_color="rgba(255, 165, 0, 0.3)", 
    stroke_width=15,                     
    stroke_color="#FFFFFF",             
    background_color="#000000",         
    width=280,
    height=280,
    drawing_mode="freedraw",
    key="canvas",
)

# ëª¨ë¸ ë¡œë“œ
model = load_model()

# "ì˜ˆì¸¡í•˜ê¸°" ë²„íŠ¼
if st.button("ì˜ˆì¸¡í•˜ê¸°"):
    if canvas_result.image_data is not None and model is not None:
        # ìº”ë²„ìŠ¤ì—ì„œ ê·¸ë¦° ì´ë¯¸ì§€ë¥¼ PIL Imageë¡œ ë³€í™˜ (ì•ŒíŒŒ ì±„ë„ ì œì™¸)
        img_pil = Image.fromarray(canvas_result.image_data.astype('uint8'), 'RGBA').convert('RGB')
        
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        img_transformed = transform(img_pil)
        
        # --- 4. ì˜ˆì¸¡ ìˆ˜í–‰ ---
        with torch.no_grad():
            # ëª¨ë¸ ì…ë ¥ì— ë§ê²Œ 1ì°¨ì› ë²¡í„°ë¡œ í¼ì¹˜ê¸°
            image_flattened = img_transformed.view(-1, 28 * 28)
            outputs = model(image_flattened)
            _, predicted = torch.max(outputs, 1)
            prediction = predicted.item()

        st.success(f"ğŸ¤– ì˜ˆì¸¡ëœ ìˆ«ì: {prediction}")
        
        # ì˜ˆì¸¡ ê²°ê³¼ì™€ í•¨ê»˜ ì›ë³¸ ì´ë¯¸ì§€ ì¶œë ¥
        st.image(img_pil, caption='ì…ë ¥í•œ ì´ë¯¸ì§€', use_column_width=True)
    elif model is None:
        st.warning("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•„ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.warning("ìˆ«ìë¥¼ ë¨¼ì € ê·¸ë ¤ì£¼ì„¸ìš”.")